# Data

If you are publishing data this is a proposed checklist to make sure your data is following suggested standards.

- [ ] Availability of Training Data
- [ ] Availability of Validation Data
- [ ] Availability of Test Data / Test split
- [ ] Availability on results Data
- [ ] Explanation on data manipulation (Exclusion/Protocol Change)
- [ ] Explanation of pre-processing
- [ ] Relevant Statistics (Number of samples/classes)
- [ ] Data is citable / Unique Identifier / DOI / Versioning
- [ ] License Specification
- [ ] Data is indexiable/searchable
- [ ] FAIR principles ( Check [go-fair](https://www.go-fair.org/fair-principles/))
- [ ] Availability of Metadata (Ideally for each file.)

For data repository we recommend to use a private new dataset in kaggle.com, until your work is ready for publication.
You can upload you data there and it has options to define a DOI, metadata and documentation so one can achieve all the marks of this list.
It also has tools to provide, simple statistics and a usuability score for your dataset.

This list was compiled based on the following references

- [The Turing Way](https://the-turing-way.netlify.app) through the projectâ€™s Zenodo archive using doi: [10.5281/zenodo.3233853.](https://doi.org/10.5281/zenodo.3233853)
- [Joelle Pineau's machine learning reproducibility checklist](https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf)
- [State of the Art: Reproducibility in Artificial Intelligence](https://www.aaai.org/GuideBook2018/17248-73943-GB.pdf)
- [Go Fair](https://www.go-fair.org/fair-principles/)